{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import sklearn\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriTraining:\n",
    "    def __init__(self, classifier):\n",
    "        if sklearn.base.is_classifier(classifier):\n",
    "            self.classifiers = [sklearn.base.clone(classifier) for i in range(3)]\n",
    "        else:\n",
    "            self.classifiers = [sklearn.base.clone(classifier[i]) for i in range(3)]\n",
    "            \n",
    "    def fit(self, L_X, L_y, U_X):\n",
    "            \n",
    "        for i in range(3):\n",
    "            sample = sklearn.utils.resample(L_data, L_label)  # BootstrapSample(L)\n",
    "            self.classifiers[i].fit(*sample)  # Learn(Si)   \n",
    "        e_prime = [0.5]*3\n",
    "        l_prime = [0]*3\n",
    "        e = [0]*3\n",
    "        update = [False]*3\n",
    "        Li_X, Li_y = [[]]*3, [[]]*3#to save proxy labeled data\n",
    "        improve = True\n",
    "        self.iter = 0\n",
    "        \n",
    "        while improve:\n",
    "            self.iter += 1#count iterations \n",
    "            \n",
    "            for i in range(3):    \n",
    "                j, k = np.delete(np.array([0,1,2]),i)\n",
    "                update[i] = False\n",
    "                e[i] = self.measure_error(L_X, L_y, j, k)\n",
    "                if e[i] < e_prime[i]:\n",
    "                    U_y_j = self.classifiers[j].predict(U_data)\n",
    "                    U_y_k = self.classifiers[k].predict(U_data)\n",
    "                    Li_X[i] = U_X[U_y_j == U_y_k]#when two models agree on the label, save it\n",
    "                    Li_y[i] = U_y_j[U_y_j == U_y_k]\n",
    "                    if l_prime[i] == 0:#no updated before\n",
    "                        l_prime[i]  = int(e[i]/(e_prime[i] - e[i]) + 1)\n",
    "                    if l_prime[i] <len(Li_y[i]):\n",
    "                        if e[i]*len(Li_y[i])<e_prime[i] * l_prime[i]:\n",
    "                            update[i] = True\n",
    "                        elif l_prime[i] > e[i]/(e_prime[i] - e[i]):\n",
    "                            L_index = np.random.choice(len(Li_y[i]), int(e_prime[i] * l_prime[i]/e[i] -1))#subsample from proxy labeled data\n",
    "                            Li_X[i], Li_y[i] = Li_X[i][L_index], Li_y[i][L_index]\n",
    "                            update[i] = True\n",
    "             \n",
    "            for i in range(3):\n",
    "                if update[i]:\n",
    "                    self.classifiers[i].fit(np.append(L_X,Li_X[i],axis=0), np.append(L_y, Li_y[i], axis=0))#train the classifier on integrated dataset\n",
    "                    e_prime[i] = e[i]\n",
    "                    l_prime[i] = len(Li_y[i])\n",
    "    \n",
    "            if update == [False]*3:\n",
    "                improve = False#if no classifier was updated, no improvement\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.asarray([self.classifiers[i].predict(X) for i in range(3)])\n",
    "        pred[0][pred[1]==pred[2]] = pred[1][pred[1]==pred[2]]\n",
    "        return pred[0]\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return sklearn.metrics.accuracy_score(y, self.predict(X))\n",
    "        \n",
    "    def measure_error(self, X, y, j, k):\n",
    "        j_pred = self.classifiers[j].predict(X)\n",
    "        k_pred = self.classifiers[k].predict(X)\n",
    "        wrong_index =np.logical_and(j_pred != y, k_pred==j_pred)#model_j and model_k make the same wrong prediction\n",
    "        #wrong_index =np.logical_and(j_pred != y_test, k_pred!=y_test)\n",
    "        return sum(wrong_index)/sum(j_pred == k_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriTrainingwDisagreement():\n",
    "\n",
    "    def __init__(self, classifier):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            classifier - classifier, with .fit, .predict API (refer to classifiers of sklearn)\n",
    "        \"\"\"\n",
    "        # Initialize\n",
    "        if sklearn.base.is_classifier(classifier):\n",
    "            self.clf = [sklearn.base.clone(classifier) for i in range(3)]\n",
    "        else:\n",
    "            self.clf = [sklearn.base.clone(classifier[i]) for i in range(3)]\n",
    "\n",
    "    def measure_error(self, j, k):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                j - int, classifier index\n",
    "                k - int, classifier index\n",
    "        return:\n",
    "                float, classification_error\n",
    "        \"\"\"\n",
    "        y_predict_j = self.clf[j].predict(self.X_label)\n",
    "        y_predict_k = self.clf[k].predict(self.X_label)\n",
    "        return (1 - np.sum((y_predict_j == y_predict_k) & (y_predict_j == self.y_label)) / np.sum(y_predict_j == y_predict_k))\n",
    "\n",
    "    def fit(self, X_label, y_label, X_unlabel):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                X_label - labeled train feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "                y_label - labeled train label vector (ndarray of size, # of samples), labels are numeric numbers\n",
    "                X_unlabel - test feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "        \"\"\"        \n",
    "\n",
    "        self.X_label = X_label\n",
    "        self.y_label = y_label\n",
    "\n",
    "        classification_error_current = [0.5, 0.5, 0.5]\n",
    "        classification_error = [0.5, 0.5, 0.5]\n",
    "        pseudo_label_size_current = [0, 0, 0]\n",
    "        pseudo_label_size = [0, 0, 0]\n",
    "        # pseudo_label_index used to compare and check if tri-training can be stopped, when two iterations have the same label_index, means tri-training can be stopped\n",
    "        X_pseudo_label_index = [[], [], []]\n",
    "        X_pseudo_label_index_current = [[], [], []]\n",
    "\n",
    "        feature_size = self.X_label.shape[1]\n",
    "\n",
    "        # Train each classifier with bootstrampped subset\n",
    "        for i in range(3):\n",
    "            X_resample, y_resample = sklearn.utils.resample(self.X_label, self.y_label)  # BootstrapSample(L)\n",
    "            self.clf[i].fit(X_resample, y_resample)  # Learn(Si)\n",
    "\n",
    "        iteration = 0\n",
    "        while (True):\n",
    "\n",
    "            update = [False, False, False]\n",
    "\n",
    "            iteration = iteration + 1\n",
    "            for i in range(3):\n",
    "                X_pseudo_label_index_current[i] = X_pseudo_label_index[i]\n",
    "\n",
    "            # Step3.1 Set Li = empty set, Li denotes the new pseudo label set determined by tri-training iteration for classifier i\n",
    "            # X_pseudo_label_index, contains the data record index (in the full unlabelled set) of the new pseudo label set determined by tri-training iteration for classifier i\n",
    "            # X_pseudo_label, contains the features for new pseudo label set determined by tri-training iteration for classifier i\n",
    "            # y_pseudo_label, contains the labels (not ground truth label, but pseudo label calculated by tri-training iteration) for new pseudo label set determined by tri-training iteration for classifier i\n",
    "            X_pseudo_label_index = [[], [], []]\n",
    "            X_pseudo_label = [[], [], []]\n",
    "            y_pseudo_label = [[], [], []]\n",
    "\n",
    "            # Step 3.2 Loop through all the data record in unlabelled set\n",
    "            for i in range(3):\n",
    "                j, k = np.delete(np.array([0, 1, 2]), i)\n",
    "                classification_error[i] = self.measure_error(j, k)\n",
    "                if classification_error[i] < classification_error_current[i]:\n",
    "                    # Step 3.2 If classifier j,k aggrees with the label for one data record, and not agree with classifier i, in unlabelled set,\n",
    "                    # then add the data record into Li                    \n",
    "                    y_predict_j = self.clf[j].predict(X_unlabel)\n",
    "                    y_predict_k = self.clf[k].predict(X_unlabel)\n",
    "                    y_predict_i = self.clf[i].predict(X_unlabel)\n",
    "                    y_pseudo_label[i] = y_predict_j[np.logical_and(y_predict_j==y_predict_k,y_predict_j!=y_predict_i)]\n",
    "                    X_pseudo_label_index[i] = np.where(np.logical_and(y_predict_j==y_predict_k,y_predict_j!=y_predict_i))\n",
    "                    \n",
    "                    pseudo_label_size[i] = len(X_pseudo_label_index[i])\n",
    "                    #print(\"classification_error: {}, classification_error_current: {}, pseudo_label_size: {}, pseudo_label_size_current: {}\".format(classification_error[i], classification_error_current[i], pseudo_label_size[i],pseudo_label_size_current[i]))\n",
    "\n",
    "                    if pseudo_label_size_current[i] == 0:\n",
    "                        pseudo_label_size_current[i] = math.floor(classification_error[i] / (classification_error_current[i] - classification_error[i]) + 1)\n",
    "                    if pseudo_label_size_current[i] < pseudo_label_size[i]:\n",
    "                        if ((classification_error[i] * pseudo_label_size[i]) < (classification_error_current[i] * pseudo_label_size_current[i])):\n",
    "                            update[i] = True\n",
    "                        elif pseudo_label_size_current[i] > (classification_error[i] / (classification_error_current[i] - classification_error[i])):\n",
    "                            resample_size = math.ceil(classification_error_current[i] * pseudo_label_size_current[i] / classification_error[i] - 1)\n",
    "                            X_pseudo_label_index[i], y_pseudo_label[i] = sklearn.utils.resample(X_pseudo_label_index[i],y_pseudo_label[i],replace=False,n_samples=resample_size)\n",
    "                            pseudo_label_size[i] = len(X_pseudo_label_index[i])\n",
    "                            update[i] = True\n",
    "\n",
    "            # Step 3.3 Train all the three classifiers with Li + original labelled data set\n",
    "            for i in range(3):\n",
    "                if update[i] == True:\n",
    "                    #print(\"number of pseudo labels added for classifier {} is: {}\".format(i,len(X_pseudo_label_index[i])))\n",
    "                    X_pseudo_label[i] = np.array(X_unlabel[X_pseudo_label_index[i]])\n",
    "                    self.clf[i].fit(np.concatenate((X_pseudo_label[i], self.X_label), axis=0),np.concatenate((np.array(y_pseudo_label[i]), self.y_label), axis=0))\n",
    "                    classification_error_current[i] = classification_error[i]\n",
    "                    pseudo_label_size_current[i] = pseudo_label_size[i]\n",
    "\n",
    "            # Stop tri-training process, if the pseudo label data set added in current tri-training iteration\n",
    "            # is the same for last tri-training iteration for all classifiers\n",
    "            if (np.array_equal(X_pseudo_label_index[0], X_pseudo_label_index_current[0]) & np.array_equal(X_pseudo_label_index[1], X_pseudo_label_index_current[1]) \n",
    "                    & np.array_equal(X_pseudo_label_index[2], X_pseudo_label_index_current[2])):\n",
    "                break\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                X_test - test feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "        return:\n",
    "                array of size (# of test samples), with values as predicted label 1 or 0\n",
    "        \"\"\"\n",
    "        I = self.clf[0].predict(X_test)\n",
    "        J = self.clf[1].predict(X_test)\n",
    "        K = self.clf[2].predict(X_test)\n",
    "        I[J == K] = J[J == K]\n",
    "        return I\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                X_test - test feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "                y_test - test label vector (ndarray of size, # of samples), labels are numeric numbers\n",
    "        return:\n",
    "                float, accuracy_score of predicted value by the tri-training (with disagreement) classifier against groud truth\n",
    "        \"\"\"\n",
    "        \n",
    "        return sklearn.metrics.accuracy_score(y_test, self.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = {}\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "classifier['DecisionTree'] = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(data, label, rate, test_rate=0.2):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size = test_rate, random_state=0)\n",
    "\n",
    "    rng = np.random.RandomState(0)#to make same index every time\n",
    "    labeled_index = rng.rand(len(y_train)) < rate#in training set, choose 20% as labeled data\n",
    "    unlabeled_index = np.logical_not(labeled_index)\n",
    "    L_data = X_train[labeled_index]#data of L\n",
    "    L_label = y_train[labeled_index]#lable of L\n",
    "    U_data = X_train[unlabeled_index]#data of U\n",
    "    return L_data, L_label, U_data, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haber Sınıflandırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "\n",
    "data = pd.read_csv('C:/Users/Hilal KAYA/Downloads/turkish_text_data/turkish_text_data.csv', encoding='utf-8')\n",
    "data['labels'] = pd.factorize(data.category)[0]\n",
    "\n",
    "training = data.groupby('category').apply(lambda x : x.sample(frac = 0.5))\n",
    "\n",
    "training_texts = training.text.values\n",
    "training_labels = training.labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dunya</th>\n",
       "      <th>1125</th>\n",
       "      <td>dunya</td>\n",
       "      <td>azerbaycan ve türkiye ortak ordu kursun azerb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>dunya</td>\n",
       "      <td>rusya da şok suikast ! suriye ye askeri malze...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>dunya</td>\n",
       "      <td>mahalle arası çatışmalarda 3 ölü beyrut taki ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>dunya</td>\n",
       "      <td>iskoçlar bağımsızlık istemiyor ingiltere ile ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>dunya</td>\n",
       "      <td>suriye nin kimyasal silahlarıyla ilgili sert ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category                                               text  \\\n",
       "category                                                                    \n",
       "dunya    1125   dunya    azerbaycan ve türkiye ortak ordu kursun azerb...   \n",
       "         1396   dunya    rusya da şok suikast ! suriye ye askeri malze...   \n",
       "         1268   dunya    mahalle arası çatışmalarda 3 ölü beyrut taki ...   \n",
       "         1061   dunya    iskoçlar bağımsızlık istemiyor ingiltere ile ...   \n",
       "         1224   dunya    suriye nin kimyasal silahlarıyla ilgili sert ...   \n",
       "\n",
       "               labels  \n",
       "category               \n",
       "dunya    1125       1  \n",
       "         1396       1  \n",
       "         1268       1  \n",
       "         1061       1  \n",
       "         1224       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2450, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category  text\n",
       "labels                \n",
       "0            350   350\n",
       "1            350   350\n",
       "2            350   350\n",
       "3            350   350\n",
       "4            350   350\n",
       "5            350   350\n",
       "6            350   350"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.groupby(\"labels\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            labels\n",
       "count  2450.000000\n",
       "mean      3.000000\n",
       "std       2.000408\n",
       "min       0.000000\n",
       "25%       1.000000\n",
       "50%       3.000000\n",
       "75%       5.000000\n",
       "max       6.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-uncased', do_lower_case=True)\n",
    "sentences = data.text.values\n",
    "max_len = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in training_texts:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                     \n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 250,      \n",
    "                        pad_to_max_length = True,\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True, \n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(training_labels)\n",
    "\n",
    "dataset['bert'] = {'X': input_ids, 'y':labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: bert torch.Size([2398, 250])\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.1\n",
      "TriTraining test error 0.02572916666666667\n",
      "TriTraining test score 0.9742708333333333\n",
      "TriTraining test error 0.05062500000000001\n",
      "TriTraining test score 0.949375\n",
      "TriTraining test error 0.0765625\n",
      "TriTraining test score 0.9234375\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "\n",
    "for d in dataset:\n",
    "    for c in classifier:       \n",
    "        print('dataset:', d, dataset[d]['X'].shape)\n",
    "        print('classifier:', c)\n",
    "        print('label_rate:', r)\n",
    "        error = np.zeros([4,20])\n",
    "        for i in range(3):\n",
    "            L_data, L_label, U_data, X_test, y_test = data_process(dataset[d]['X'], dataset[d]['y'], 0.1)\n",
    "            m1 = TriTraining(classifier[c])\n",
    "            m1.fit(L_data, L_label, U_data)\n",
    "            error[0, i] = 1-m1.score(X_test, y_test)  \n",
    "            e = np.mean(error, axis = 1)\n",
    "            print('TriTraining test error', e[0])\n",
    "            print('TriTraining test score', 1 - e[0])\n",
    "            \n",
    "        test_info = {'dataset': d+str(dataset[d]['X'].shape), 'classifier': c, 'label_rate': r}\n",
    "        errors = {'TriTraining': e[0]}\n",
    "        if results is None:\n",
    "            results = pd.DataFrame([{**test_info, **errors}])\n",
    "        else:\n",
    "            results.loc[len(results.index)] = {**test_info, **errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: bert torch.Size([2398, 250])\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.1\n",
      "TriTraining Disagree test error 0.022604166666666665\n",
      "TriTraining Disagree test score 0.9773958333333334\n",
      "TriTraining Disagree test error 0.04802083333333333\n",
      "TriTraining Disagree test score 0.9519791666666667\n",
      "TriTraining Disagree test error 0.07364583333333333\n",
      "TriTraining Disagree test score 0.9263541666666667\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "\n",
    "for d in dataset:\n",
    "    for c in classifier:   \n",
    "        print('dataset:', d, dataset[d]['X'].shape)\n",
    "        print('classifier:', c)\n",
    "        print('label_rate:', r)\n",
    "        error = np.zeros([4,20])\n",
    "        for i in range(3):\n",
    "            L_data, L_label, U_data, X_test, y_test = data_process(dataset[d]['X'], dataset[d]['y'], 0.1)\n",
    "            m1 = TriTrainingwDisagreement(classifier[c])\n",
    "            m1.fit(L_data, L_label, U_data)\n",
    "            error[0, i] = 1-m1.score(X_test, y_test)    \n",
    "            e = np.mean(error, axis = 1)\n",
    "            print('TriTraining Disagree test error', e[0])\n",
    "            print('TriTraining Disagree test score', 1 - e[0])\n",
    "            \n",
    "        test_info = {'dataset': d+str(dataset[d]['X'].shape), 'classifier': c, 'label_rate': r}\n",
    "        errors = {'TriTraining Disagree': e[0]}\n",
    "        if results is None:\n",
    "            results = pd.DataFrame([{**test_info, **errors}])\n",
    "        else:\n",
    "            results.loc[len(results.index)] = {**test_info, **errors}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duygudurum Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biri bana bu filmde benim anlamadigim bisey ol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ya çocuklar ilk filmin sonunda büyüdüler ya bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film biraz daha uzun sürse harbi kiyameti göre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pek orjinal bi cinayet yok ama orjinal oyuncul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>film tek kelimeyle muhtesemdi heleki sonundaki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  Label\n",
       "0  biri bana bu filmde benim anlamadigim bisey ol...      0\n",
       "1  ya çocuklar ilk filmin sonunda büyüdüler ya bu...      1\n",
       "2  film biraz daha uzun sürse harbi kiyameti göre...      0\n",
       "3  pek orjinal bi cinayet yok ama orjinal oyuncul...      0\n",
       "4  film tek kelimeyle muhtesemdi heleki sonundaki...      1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"C:/Users/Hilal KAYA/Downloads/sentiment/train.csv\",index_col=[0],encoding=\"windows-1252\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "training = data.groupby('Label').apply(lambda x : x.sample(frac = 0.3))\n",
    "training_texts = training.comment.values\n",
    "training_labels = training.Label.values\n",
    "print(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2398, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in training_texts:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                     \n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 250,      \n",
    "                        pad_to_max_length = True,\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True, \n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(training_labels)\n",
    "\n",
    "dataset['bert'] = {'X': input_ids, 'y':labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bert': {'X': tensor([[    2, 22467,  4767,  ...,     0,     0,     0],\n",
      "        [    2, 10367,  2013,  ...,     0,     0,     0],\n",
      "        [    2, 10520,  3371,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  8708, 19137,  ...,     0,     0,     0],\n",
      "        [    2,  2083,  3776,  ...,     0,     0,     0],\n",
      "        [    2, 26382,  6191,  ...,     0,     0,     0]]), 'y': tensor([0, 0, 0,  ..., 1, 1, 1])}}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: bert torch.Size([2398, 250])\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.1\n",
      "TriTraining test error 0.025312499999999998\n",
      "TriTraining test score 0.9746875\n",
      "TriTraining test error 0.0503125\n",
      "TriTraining test score 0.9496875\n",
      "TriTraining test error 0.07510416666666667\n",
      "TriTraining test score 0.9248958333333334\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "\n",
    "for d in dataset:\n",
    "    for c in classifier:       \n",
    "        print('dataset:', d, dataset[d]['X'].shape)\n",
    "        print('classifier:', c)\n",
    "        print('label_rate:', r)\n",
    "        error = np.zeros([4,20])\n",
    "        for i in range(3):\n",
    "            L_data, L_label, U_data, X_test, y_test = data_process(dataset[d]['X'], dataset[d]['y'], 0.1)\n",
    "            m1 = TriTraining(classifier[c])\n",
    "            m1.fit(L_data, L_label, U_data)\n",
    "            error[0, i] = 1-m1.score(X_test, y_test)  \n",
    "            e = np.mean(error, axis = 1)\n",
    "            print('TriTraining test error', e[0])\n",
    "            print('TriTraining test score', 1 - e[0])\n",
    "            \n",
    "        test_info = {'dataset': d+str(dataset[d]['X'].shape), 'classifier': c, 'label_rate': r}\n",
    "        errors = {'TriTraining': e[0]}\n",
    "        if results is None:\n",
    "            results = pd.DataFrame([{**test_info, **errors}])\n",
    "        else:\n",
    "            results.loc[len(results.index)] = {**test_info, **errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: bert torch.Size([2398, 250])\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.1\n",
      "TriTraining Disagree test error 0.02364583333333333\n",
      "TriTraining Disagree test score 0.9763541666666666\n",
      "TriTraining Disagree test error 0.04895833333333333\n",
      "TriTraining Disagree test score 0.9510416666666667\n",
      "TriTraining Disagree test error 0.07447916666666668\n",
      "TriTraining Disagree test score 0.9255208333333333\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "\n",
    "for d in dataset:\n",
    "    for c in classifier:   \n",
    "        print('dataset:', d, dataset[d]['X'].shape)\n",
    "        print('classifier:', c)\n",
    "        print('label_rate:', r)\n",
    "        error = np.zeros([4,20])\n",
    "        for i in range(3):\n",
    "            L_data, L_label, U_data, X_test, y_test = data_process(dataset[d]['X'], dataset[d]['y'], 0.1)\n",
    "            m1 = TriTrainingwDisagreement(classifier[c])\n",
    "            m1.fit(L_data, L_label, U_data)\n",
    "            error[0, i] = 1-m1.score(X_test, y_test)    \n",
    "            e = np.mean(error, axis = 1)\n",
    "            print('TriTraining Disagree test error', e[0])\n",
    "            print('TriTraining Disagree test score', 1 - e[0])\n",
    "            \n",
    "        test_info = {'dataset': d+str(dataset[d]['X'].shape), 'classifier': c, 'label_rate': r}\n",
    "        errors = {'TriTraining Disagree': e[0]}\n",
    "        if results is None:\n",
    "            results = pd.DataFrame([{**test_info, **errors}])\n",
    "        else:\n",
    "            results.loc[len(results.index)] = {**test_info, **errors}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>Sen, efendim, benim kahramanımsın. Hangi sayfa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>KADIN ÇALIŞMAYA ÇALIŞMADAN ÖNCE COCKSUCKER</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00070ef96486d6f9</td>\n",
       "      <td>Oh, ve yukarıdaki kız benimle tartışmalara baş...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey adamım, gerçekten savaşı düzenlemeye çalış...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00173958f46763a2</td>\n",
       "      <td>TFD\\n\\nSanýrým sadece düţündük. Sanırım birbir...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0001d958c54c6e35  Sen, efendim, benim kahramanımsın. Hangi sayfa...      0   \n",
       "1  0002bcb3da6cb337         KADIN ÇALIŞMAYA ÇALIŞMADAN ÖNCE COCKSUCKER      1   \n",
       "2  00070ef96486d6f9  Oh, ve yukarıdaki kız benimle tartışmalara baş...      0   \n",
       "3  000113f07ec002fd  Hey adamım, gerçekten savaşı düzenlemeye çalış...      0   \n",
       "4  00173958f46763a2  TFD\\n\\nSanýrým sadece düţündük. Sanırım birbir...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"C:/Users/Hilal KAYA/Downloads/toxicComment/toxicComment.csv\",index_col=[0],encoding=\"utf-8\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cat = pd.concat([\n",
    "    data[['comment_text', 'toxic']], \n",
    "]).sample(n=3000).reset_index(drop=True)\n",
    "\n",
    "train_data = train_cat\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "training_texts = train_data.comment_text.values\n",
    "training_labels = train_data.toxic.values\n",
    "print(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in training_texts:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                     \n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 250,      \n",
    "                        pad_to_max_length = True,\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True, \n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(training_labels)\n",
    "\n",
    "dataset['bert'] = {'X': input_ids, 'y':labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bert': {'X': tensor([[    2, 18467,  2536,  ...,     0,     0,     0],\n",
      "        [    2,    30,  3716,  ...,     0,     0,     0],\n",
      "        [    2,  2011,  7959,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  2737, 31874,  ...,     0,     0,     0],\n",
      "        [    2,     6,    30,  ...,     0,     0,     0],\n",
      "        [    2,     6,    30,  ...,     0,     0,     0]]), 'y': tensor([0, 0, 0,  ..., 0, 1, 0])}}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: bert torch.Size([3000, 250])\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.1\n",
      "TriTraining test error 0.0052499999999999995\n",
      "TriTraining test score 0.99475\n",
      "TriTraining test error 0.012166666666666664\n",
      "TriTraining test score 0.9878333333333333\n",
      "TriTraining test error 0.01783333333333333\n",
      "TriTraining test score 0.9821666666666666\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "\n",
    "for d in dataset:\n",
    "    for c in classifier:       \n",
    "        print('dataset:', d, dataset[d]['X'].shape)\n",
    "        print('classifier:', c)\n",
    "        print('label_rate:', r)\n",
    "        error = np.zeros([4,20])\n",
    "        for i in range(3):\n",
    "            L_data, L_label, U_data, X_test, y_test = data_process(dataset[d]['X'], dataset[d]['y'], 0.1)\n",
    "            m1 = TriTraining(classifier[c])\n",
    "            m1.fit(L_data, L_label, U_data)\n",
    "            error[0, i] = 1-m1.score(X_test, y_test)  \n",
    "            e = np.mean(error, axis = 1)\n",
    "            print('TriTraining test error', e[0])\n",
    "            print('TriTraining test score', 1 - e[0])\n",
    "            \n",
    "        test_info = {'dataset': d+str(dataset[d]['X'].shape), 'classifier': c, 'label_rate': r}\n",
    "        errors = {'TriTraining': e[0]}\n",
    "        if results is None:\n",
    "            results = pd.DataFrame([{**test_info, **errors}])\n",
    "        else:\n",
    "            results.loc[len(results.index)] = {**test_info, **errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: bert torch.Size([3000, 250])\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.1\n",
      "TriTraining Disagree test error 0.008000000000000002\n",
      "TriTraining Disagree test score 0.992\n",
      "TriTraining Disagree test error 0.014083333333333337\n",
      "TriTraining Disagree test score 0.9859166666666667\n",
      "TriTraining Disagree test error 0.0195\n",
      "TriTraining Disagree test score 0.9805\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "\n",
    "for d in dataset:\n",
    "    for c in classifier:   \n",
    "        print('dataset:', d, dataset[d]['X'].shape)\n",
    "        print('classifier:', c)\n",
    "        print('label_rate:', r)\n",
    "        error = np.zeros([4,20])\n",
    "        for i in range(3):\n",
    "            L_data, L_label, U_data, X_test, y_test = data_process(dataset[d]['X'], dataset[d]['y'], 0.1)\n",
    "            m1 = TriTrainingwDisagreement(classifier[c])\n",
    "            m1.fit(L_data, L_label, U_data)\n",
    "            error[0, i] = 1-m1.score(X_test, y_test)    \n",
    "            e = np.mean(error, axis = 1)\n",
    "            print('TriTraining Disagree test error', e[0])\n",
    "            print('TriTraining Disagree test score', 1 - e[0])\n",
    "            \n",
    "        test_info = {'dataset': d+str(dataset[d]['X'].shape), 'classifier': c, 'label_rate': r}\n",
    "        errors = {'TriTraining Disagree': e[0]}\n",
    "        if results is None:\n",
    "            results = pd.DataFrame([{**test_info, **errors}])\n",
    "        else:\n",
    "            results.loc[len(results.index)] = {**test_info, **errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
